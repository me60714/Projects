Create an ETL pipeline to extract, transform, and load customer data from a CSV file into a database. This project simulates a common real-world scenario where you need to process and store customer information.

Steps to Implement:

Data Extraction (E):
1. Write a Python script that generates a synthetic customer dataset and saves it to a CSV file.
2. Write a Python script to read data from the CSV file.

Data Transformation (T):
1. Perform data cleansing and transformation. Including tasks like handling missing values, standardizing formats, and generating derived features.

Data Loading (L):
1. Set up a PostgreSQL database.
2. Create a table schema to store the customer data.
3. Write a Python script to insert the transformed data into the database.

Data Analysis and Visualization:
